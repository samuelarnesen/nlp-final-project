{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Transformer 1.ipynb  dataloader.py\r\n",
      "\u001b[1m\u001b[34m__pycache__\u001b[m\u001b[m/               models.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load every dataset manually and create torch objects\n",
    "comment_df = pd.read_csv(\"../data/attack_annotated_comments.tsv\", sep ='\\t')\n",
    "body_df = pd.read_csv(\"../data/fake_news_bodies.csv\")\n",
    "stance_df = pd.read_csv(\"../data/fake_news_stances.csv\")\n",
    "vocab = Vocabulary([comment_df[\"comment\"], body_df[\"articleBody\"], stance_df[\"Headline\"]])\n",
    "annotation_df = pd.read_csv(\"../data/attack_annotations.tsv\",  sep='\\t')\n",
    "\n",
    "wiki_dataset = WikiDataset(comment_df, annotation_df, vocab)\n",
    "fake_news_dataset = FakeNewsDataset(body_df, stance_df, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                            comment  year  logged_in  \\\n",
       "0   37675  `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002      False   \n",
       "1   44816  `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...  2002      False   \n",
       "\n",
       "        ns  sample  split  \n",
       "0  article  random  train  \n",
       "1  article  random  train  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>sentence_as_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>[2, 126, 2627, 7088, 36713, 1541, 126, 64723, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "      <td>[2, 978, 9959, 301, 27551, 181, 184, 243, 21, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody  \\\n",
       "0        0  A small meteorite crashed into a wooded area i...   \n",
       "1        4  Last week we hinted at what was to come as Ebo...   \n",
       "\n",
       "                                     sentence_as_idx  \n",
       "0  [2, 126, 2627, 7088, 36713, 1541, 126, 64723, ...  \n",
       "1  [2, 978, 9959, 301, 27551, 181, 184, 243, 21, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance\n",
       "0  Police find mass graves with at least '15 bodi...      712  unrelated\n",
       "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stance_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unrelated', 'agree', 'disagree', 'discuss'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check label correspondence\n",
    "stance_df['Stance'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>quoting_attack</th>\n",
       "      <th>recipient_attack</th>\n",
       "      <th>third_party_attack</th>\n",
       "      <th>other_attack</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>1362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37675</td>\n",
       "      <td>2408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id  worker_id  quoting_attack  recipient_attack  third_party_attack  \\\n",
       "0   37675       1362             0.0               0.0                 0.0   \n",
       "1   37675       2408             0.0               0.0                 0.0   \n",
       "\n",
       "   other_attack  attack  \n",
       "0           0.0     0.0  \n",
       "1           0.0     0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73130953, 0.07360122, 0.01680941, 0.17827984])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check label bias\n",
    "fake_news_dataset.y.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88270731, 0.11729269])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check label bias\n",
    "wiki_dataset.y.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Once the data is loaded, prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple transformer model, cant be used for classification\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 64\n",
    "nhead = 1\n",
    "hidden_dim = 32\n",
    "num_layers = 1\n",
    "feedforward_dim = 64\n",
    "def model_from_dataset(dataset):\n",
    "    labels = len(dataset[0][1])\n",
    "    model = TransformerClassifier(vocab_size, labels, embedding_dim, nhead, feedforward_dim, num_layers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[332357,  93304, 213199, 260793, 113526, 368237,  89275, 150544,   5370,\n",
      "         320066, 187463, 462218, 172429,  91137,  53367, 225638, 425222, 397346,\n",
      "         335718, 323157,  12196,  38956, 451840, 426789, 188464],\n",
      "        [402335, 111952, 271401, 302040,   8375,  67705,  71914, 450786, 471491,\n",
      "         211672, 467741, 227187,  80995, 281732, 420791, 358241, 375711,  83140,\n",
      "         264232, 365294, 109667,  58405, 166355,  81902, 209890],\n",
      "        [165047, 349506, 133902, 303338,  47538, 125836, 387747, 256494, 227820,\n",
      "         246814, 302028, 370187, 183471, 307331, 102729, 321903,    737, 174726,\n",
      "         457255,  61494,  14260, 336013, 448204, 422765, 459836],\n",
      "        [124355, 165645, 392727, 309833, 200424, 305715, 117722, 414013, 261790,\n",
      "         108170, 382767, 147655, 266789, 216114, 275488, 176817,  52150, 440249,\n",
      "         223400, 293773, 440226,  65888, 395575, 117996, 176921],\n",
      "        [139807,  99777, 233510,  51941, 445060, 123658, 300440, 398914,  84150,\n",
      "         385536, 230100, 330388, 393145,  11145,   4607, 146845, 416609, 449888,\n",
      "         431724, 203997, 120750, 288285, 473242, 421382, 262001]])\n",
      "tensor([[0.8260, 0.1306, 0.0434],\n",
      "        [0.8916, 0.0035, 0.1049],\n",
      "        [0.6443, 0.0097, 0.3460],\n",
      "        [0.8854, 0.0673, 0.0473],\n",
      "        [0.2750, 0.4570, 0.2680]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = model_from_dataset([(1, np.array([0, 1, 0]))]) # fake dataset with 3 labels\n",
    "nparr = np.random.randint(0, vocab_size, size=(5, 25))\n",
    "x = torch.from_numpy(nparr)\n",
    "print(x)\n",
    "print(model(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once the models are working, we can implement our train method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for training given model on given dataset\n",
    "def train(model, dataset, batch_size=32, epochs=10, lr=0.1):\n",
    "    # TEMPORARY CODE: make x's equal length\n",
    "    max_len = 0\n",
    "    for (x,y) in dataset:\n",
    "        if len(x) > max_len:\n",
    "            max_len = len(x)\n",
    "    print(\"start\")\n",
    "    t = time.time()\n",
    "    clean_dataset = []\n",
    "    for (x,y) in dataset: clean_dataset.append((list(x) + (max_len - len(x))*[0], list(y)))\n",
    "    print(\"stop\", time.time() - t)\n",
    "    print(clean_dataset)\n",
    "    return\n",
    "    # END OF TEMPORARY CODE\n",
    "    dataloader = DataLoader(clean_dataset, batch_size=batch_size, shuffle=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "    model.train() # Turn on the train mode\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.\n",
    "        start_time = time.time()\n",
    "        for data in dataloader: # different shuffle each time\n",
    "            x_batch, y_batch = data\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = criterion(output.view(-1, ntokens), y_batch)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        elapsed = time.time() - start_time\n",
    "        print('| epoch {:3d} | {:5d}/{:5d} samples | '\n",
    "              'lr {:02.2f} | time {:5.2f} | loss {:5.2f}'.format(epoch, i, \n",
    "                len(train_data), scheduler.get_lr()[0], elapsed, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/johnhallman/mlcourse/mlenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-46-33f1aa94e01e>\", line 1, in <module>\n",
      "    train(model, wiki_dataset)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johnhallman/mlcourse/mlenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johnhallman/mlcourse/mlenv/bin/../lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '<ipython-input-46-33f1aa94e01e>'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johnhallman/mlcourse/mlenv/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/johnhallman/mlcourse/mlenv/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/johnhallman/mlcourse/mlenv/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/Users/johnhallman/mlcourse/mlenv/bin/../lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "train(model, wiki_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_dataset[0:2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
